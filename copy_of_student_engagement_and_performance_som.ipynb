{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronincodex/Student-Engagement-and-Performance-SOM/blob/main/copy_of_student_engagement_and_performance_som.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgP9fZreV_iq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import missingno as msno\n",
        "import seaborn as sn\n",
        "\n",
        "from numpy.ma.core import ceil\n",
        "from scipy.spatial import distance #distance calculation\n",
        "from sklearn.preprocessing import MinMaxScaler #normalisation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score #scoring\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, colors\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp95uJD-eBxH",
        "outputId": "7f545c19-ba22-4707-ca67-c617353ff7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Engagement Data Set\n",
        "data_engagement = \"Student_Engagement.csv\"\n",
        "data_performance = \"Student_performance.csv\""
      ],
      "metadata": {
        "id": "ogybnN-7WWiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance"
      ],
      "metadata": {
        "id": "CFnyzTasGY94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data"
      ],
      "metadata": {
        "id": "gHznN4L_GfyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_performance = pd.read_csv('/content/sample_data/Student_Performance.csv')\n",
        "data_performance = data_performance.drop([\"Student ID\"],axis=1)\n",
        "data_performance.head()"
      ],
      "metadata": {
        "id": "LiLtlKZ3dL6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for missing value"
      ],
      "metadata": {
        "id": "WnPOK6F6Gl1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gWHuxOWJGeTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(data_performance,figsize=(10,3))\n"
      ],
      "metadata": {
        "id": "LUFFvWB7e2BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation between Features"
      ],
      "metadata": {
        "id": "MhnLHeDWGrFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continiousData = data_performance.iloc[:,:-1]\n",
        "continiousData.head()\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
        "fig.set_size_inches(20, 15)\n",
        "sn.boxplot(data=continiousData,orient=\"v\",ax=axes)"
      ],
      "metadata": {
        "id": "IuteYbcDfxt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "corrMatt = data_performance.corr()\n",
        "mask = np.array(corrMatt)\n",
        "mask[np.tril_indices_from(mask)] = False\n",
        "fig,ax= plt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "sn.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True)"
      ],
      "metadata": {
        "id": "9OhDdyUSG1oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "_Xvd_a-gHD_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization\n",
        "def minmax_scaler(data):\n",
        "  scaler = MinMaxScaler()\n",
        "  scaled = scaler.fit_transform(data)\n",
        "  return scaled\n",
        "\n",
        "normalized_performance=minmax_scaler(data_performance.iloc[:,:-1])\n",
        "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
        "fig.set_size_inches(25, 15)\n",
        "sn.boxplot(data=normalized_performance,orient=\"v\",ax=axes)"
      ],
      "metadata": {
        "id": "-jBmaMaPgiHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering via SOM"
      ],
      "metadata": {
        "id": "0QaV7_EYKINj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SOM\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "\n",
        "class SOM(object): \n",
        "  \n",
        "  #Initialize properties\n",
        "  def __init__(self, x, y, input_dim, learning_rate, radius, num_iter=111):\n",
        "    self._x = x\n",
        "    self._y = y\n",
        "    self._learning_rate = float(learning_rate)\n",
        "    self._radius = float(radius)\n",
        "    self._num_iter = num_iter\n",
        "    self._graph = tf.Graph()\n",
        "\n",
        "    #Initialize graph\n",
        "    with self._graph.as_default():\n",
        "\n",
        "        #Initializing variables and placeholders\n",
        "        self._weights = tf.Variable(tf.random_normal([x*y, input_dim]))\n",
        "        self._locations = self._generate_index_matrix(x, y)\n",
        "        self._input = tf.placeholder(\"float\", [input_dim])\n",
        "        self._iter_input = tf.placeholder(\"float\")\n",
        "\n",
        "        #Calculating BMU\n",
        "        input_matix = tf.stack([self._input for i in range(x*y)])\n",
        "        distances = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self._weights, input_matix), 2), 1))\n",
        "        bmu = tf.argmin(distances, 0)\n",
        "\n",
        "        #Get BMU location\n",
        "        mask = tf.pad(tf.reshape(bmu, [1]), np.array([[0, 1]]))\n",
        "        size = tf.cast(tf.constant(np.array([1, 2])), dtype=tf.int64)\n",
        "        bmu_location = tf.reshape(tf.slice(self._locations, mask, size), [2])\n",
        "\n",
        "        #Calculate learning rate and radius\n",
        "        decay_function = tf.subtract(1.0, tf.div(self._iter_input, self._num_iter))\n",
        "        _current_learning_rate = tf.multiply(self._learning_rate, decay_function)\n",
        "        _current_radius = tf.multiply(self._radius, decay_function)\n",
        "\n",
        "        #Adapt learning rate to each neuron based on position\n",
        "        bmu_matrix = tf.stack([bmu_location for i in range(x*y)])\n",
        "        bmu_distance = tf.reduce_sum(tf.pow(tf.subtract(self._locations, bmu_matrix), 2), 1)\n",
        "        neighbourhood_func = tf.exp(tf.negative(tf.div(tf.cast(bmu_distance, \"float32\"), tf.pow(_current_radius, 2))))\n",
        "        learning_rate_matrix = tf.multiply(_current_learning_rate, neighbourhood_func)\n",
        "\n",
        "        #Update all the weights\n",
        "        multiplytiplier = tf.stack([tf.tile(tf.slice(\n",
        "            learning_rate_matrix, np.array([i]), np.array([1])), [input_dim])\n",
        "                                           for i in range(x*y)])\n",
        "        delta = tf.multiply(\n",
        "            multiplytiplier,\n",
        "            tf.subtract(tf.stack([self._input for i in range(x*y)]), self._weights))                \n",
        "\n",
        "        new_weights = tf.add(self._weights, delta)\n",
        "        self._training = tf.assign(self._weights, new_weights)                                       \n",
        "\n",
        "        #Initilize session and run it\n",
        "        self._sess = tf.Session()\n",
        "        initialization = tf.global_variables_initializer()\n",
        "        self._sess.run(initialization)\n",
        "\n",
        "  def train(self, input_vects):\n",
        "      for iter_no in range(self._num_iter):\n",
        "          for input_vect in input_vects:\n",
        "              self._sess.run(self._training,\n",
        "                            feed_dict={self._input: input_vect,\n",
        "                                        self._iter_input: iter_no})\n",
        "\n",
        "      self._centroid_matrix = [[] for i in range(self._x)]\n",
        "      self._weights_list = list(self._sess.run(self._weights))\n",
        "      self._locations = list(self._sess.run(self._locations))\n",
        "      for i, loc in enumerate(self._locations):\n",
        "          self._centroid_matrix[loc[0]].append(self._weights_list[i])\n",
        "\n",
        "  def map_input(self, input_vectors):\n",
        "      return_value = []\n",
        "      for vect in input_vectors:\n",
        "          min_index = min([i for i in range(len(self._weights_list))],\n",
        "                          key=lambda x: np.linalg.norm(vect - self._weights_list[x]))\n",
        "          return_value.append(self._locations[min_index])\n",
        "      return return_value\n",
        "\n",
        "  def _generate_index_matrix(self, x,y):\n",
        "      return tf.constant(np.array(list(self._iterator(x, y))))\n",
        "\n",
        "  def _iterator(self, x, y):\n",
        "      for i in range(x):\n",
        "          for j in range(y):\n",
        "              yield np.array([i, j])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6mdKGzo2jm9",
        "outputId": "b3bdb9d3-455a-4641-cfb0-8fda12a51766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "som = SOM(x = 2, y = 1, input_dim=8, learning_rate=0.5, num_iter = 500, radius = 1.0)\n",
        "som.train(normalized_performance);"
      ],
      "metadata": {
        "id": "56odP2bC2xV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(som._weights_list)\n",
        "print(som._locations)\n",
        "cluster_centers_df = pd.DataFrame(data=som._weights_list,columns=data_performance.iloc[:,:-1].columns)\n",
        "cluster_centers_df.head()"
      ],
      "metadata": {
        "id": "_ABf__16shPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_assignment = som.map_input(normalized_performance)\n",
        "data_performance[\"cluster_som\"] = cluster_assignment\n",
        "data_performance[\"cluster\"] = data_performance.apply(lambda x: \"good\" if x[\"cluster_som\"][0]==0 else \"weak\",axis=1)\n",
        "data_performance = data_performance.drop(['cluster_som'],axis=1)\n",
        "data_performance.head(5)"
      ],
      "metadata": {
        "id": "2Y-c5S486tzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_performance_raw = pd.read_csv('/content/sample_data/Student_Performance.csv')\n",
        "data_performance['student id'] = data_performance_raw['Student ID']\n",
        "\n",
        "data_performance.head()"
      ],
      "metadata": {
        "id": "paI1oO7898TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_performance.groupby(\"cluster\").count()\n",
        "# data_performance.describe()"
      ],
      "metadata": {
        "id": "OZC3KPc2BABJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Clusters"
      ],
      "metadata": {
        "id": "xlZpF9LrJuqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pca\n",
        "pca = PCA(n_components=2)\n",
        "pca_performance = pd.DataFrame(pca.fit_transform(data_performance.iloc[:,:-3]))\n",
        "pca_performance[\"cluster\"] = data_performance[\"cluster\"]\n",
        "pca_performance.columns = ['pca0', 'pca1', 'cluster']\n",
        "# setting the dimensions of the plot\n",
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "# drawing the plot\n",
        "sn.scatterplot(data=pca_performance, x='pca0', y='pca1', hue=\"cluster\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mo3sreQ-_MDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_engagement = pd.read_csv('/content/sample_data/Student_Engagement.csv')\n",
        "data_engagement = data_engagement.drop([\"Student ID\"],axis=1)\n",
        "data_engagement.head()"
      ],
      "metadata": {
        "id": "Cf47mO8JaApL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(data_engagement,figsize=(10,3))\n"
      ],
      "metadata": {
        "id": "tVYc5ZGudDi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continiousData = data_engagement.iloc[:,:-1]\n",
        "continiousData.head()\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
        "fig.set_size_inches(50, 25)\n",
        "sn.boxplot(data=continiousData,orient=\"v\",ax=axes)"
      ],
      "metadata": {
        "id": "0nEw08GrirXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "corrMatt = data_engagement.corr()\n",
        "mask = np.array(corrMatt)\n",
        "mask[np.tril_indices_from(mask)] = False\n",
        "fig,ax= plt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "sn.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True)"
      ],
      "metadata": {
        "id": "GBdrK49pjuRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a4-GzfFIJtri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization\n",
        "def minmax_scaler(data):\n",
        "  scaler = MinMaxScaler()\n",
        "  scaled = scaler.fit_transform(data)\n",
        "  return scaled\n",
        "\n",
        "normalized_engagement=minmax_scaler(data_engagement.iloc[:,:-1])\n",
        "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
        "fig.set_size_inches(25, 15)\n",
        "sn.boxplot(data=normalized_engagement,orient=\"v\",ax=axes)"
      ],
      "metadata": {
        "id": "Kigp3R5UkFCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "som = SOM(x = 2, y = 1, input_dim=12, learning_rate=0.5, num_iter = 500, radius = 1.0)\n",
        "som.train(normalized_engagement);"
      ],
      "metadata": {
        "id": "Gtz6b9Igk5K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(som._weights_list)\n",
        "print(som._locations)\n",
        "cluster_centers_df1 = pd.DataFrame(data=som._weights_list,columns=data_engagement.iloc[:,:-1].columns)\n",
        "cluster_centers_df1.head()"
      ],
      "metadata": {
        "id": "UI2Qd5oflQJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_assignment1 = som.map_input(normalized_engagement)\n",
        "data_engagement[\"cluster_som\"] = cluster_assignment1\n",
        "data_engagement[\"cluster\"] = data_engagement.apply(lambda x: \"high\" if x[\"cluster_som\"][0]==0 else \"low\",axis=1)\n",
        "data_engagement = data_engagement.drop(['cluster_som'],axis=1)\n",
        "data_engagement.head(10)"
      ],
      "metadata": {
        "id": "DUWyhPWpl0cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_engagement_raw = pd.read_csv('/content/sample_data/Student_Engagement.csv')\n",
        "data_engagement['student id'] = data_engagement_raw['Student ID']\n",
        "\n",
        "data_engagement.head(-1)"
      ],
      "metadata": {
        "id": "4wtEYiRvphXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_engagement.groupby(\"cluster\").count()\n",
        "# data_performance.describe()"
      ],
      "metadata": {
        "id": "hGWsrX8BqA8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sAVvzGRMkuRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pca\n",
        "pca = PCA(n_components=2)\n",
        "pca_engagement = pd.DataFrame(pca.fit_transform(data_engagement.iloc[:,:-3]))\n",
        "pca_engagement[\"cluster\"] = data_engagement[\"cluster\"]\n",
        "pca_engagement.columns = ['pca0', 'pca1', 'cluster']\n",
        "# setting the dimensions of the plot\n",
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "# drawing the plot\n",
        "sn.scatterplot(data=pca_engagement, x='pca0', y='pca1', hue=\"cluster\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hY8rJeS6q9FI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}